{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc18c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.roi_heads import RoIHeads\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca775cb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TRAIN_JSON = Path(os.getenv('TRAIN_JSON'))\n",
    "VAL_JSON = Path(os.getenv('VAL_JSON'))\n",
    "TRAIN_IMAGES_DIR = Path(os.getenv('TRAIN_CLEANED'))\n",
    "VAL_IMAGES_DIR = Path(os.getenv('VAL_CLEANED'))\n",
    "OUTPUT_DIR = Path(os.getenv('OUTPUT', './outputs'))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_COCO_JSON = OUTPUT_DIR / 'train_coco.json'\n",
    "VAL_COCO_JSON = OUTPUT_DIR / 'val_coco.json'\n",
    "MODEL_SAVE_PATH = OUTPUT_DIR / 'fasterrcnn_multitask_best.pth'\n",
    "\n",
    "print(f\"✅ Train JSON: {TRAIN_JSON}\")\n",
    "print(f\"✅ Val JSON: {VAL_JSON}\")\n",
    "print(f\"✅ Train images: {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"✅ Val images: {VAL_IMAGES_DIR}\")\n",
    "print(f\"✅ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659da49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"bike_parts_detection\",\n",
    "    name=\"fasterrcnn_multitask\",\n",
    "    config={\n",
    "        \"epochs\": 20,\n",
    "        \"batch_size\": 2,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"num_workers\": 2,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"model_type\": \"MultiTaskFasterRCNN\",\n",
    "        \"backbone\": \"ResNet50-FPN\",\n",
    "        \"num_states\": 4,\n",
    "        \"state_loss_weight\": 0.5,\n",
    "        \"scheduler\": \"ReduceLROnPlateau\",\n",
    "        \"scheduler_factor\": 0.5,\n",
    "        \"scheduler_patience\": 3,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"mixed_precision\": True,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    }\n",
    ")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"✅ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✅ CUDA Version: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349b7f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_coco(json_path, images_dir, save_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f, strict=False)\n",
    "\n",
    "    coco = {\"images\": [], \"annotations\": [], \"categories\": [], \"state_categories\": []}\n",
    "    part_names = set()\n",
    "    \n",
    "    for content in data.values():\n",
    "        part_names.update(content[\"parts\"].keys())\n",
    "\n",
    "    coco[\"categories\"] = [{\"id\": i+1, \"name\": n} for i, n in enumerate(sorted(part_names))]\n",
    "    coco[\"state_categories\"] = [\n",
    "        {\"id\": 0, \"name\": \"intact\"},\n",
    "        {\"id\": 1, \"name\": \"damaged\"},\n",
    "        {\"id\": 2, \"name\": \"absent\"},\n",
    "        {\"id\": 3, \"name\": \"occluded\"},\n",
    "    ]\n",
    "    \n",
    "    ann_id = 1\n",
    "    for img_id, (img_name, content) in enumerate(data.items(), 1):\n",
    "        h, w = content[\"image\"][\"height\"], content[\"image\"][\"width\"]\n",
    "        coco[\"images\"].append({\"id\": img_id, \"file_name\": img_name, \"height\": h, \"width\": w})\n",
    "        \n",
    "        for part_name, part in content[\"parts\"].items():\n",
    "            cat_id = next(c[\"id\"] for c in coco[\"categories\"] if c[\"name\"] == part_name)\n",
    "            bbox = [\n",
    "                part[\"absolute_bounding_box\"][\"left\"],\n",
    "                part[\"absolute_bounding_box\"][\"top\"],\n",
    "                part[\"absolute_bounding_box\"][\"width\"],\n",
    "                part[\"absolute_bounding_box\"][\"height\"]\n",
    "            ]\n",
    "            coco[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"bbox\": bbox,\n",
    "                \"category_id\": cat_id,\n",
    "                \"state_id\": part[\"object_state_class\"],\n",
    "                \"area\": bbox[2] * bbox[3],\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=2)\n",
    "    print(f\"✅ Saved COCO file: {save_path} ({len(coco['images'])} images, {len(coco['annotations'])} annotations)\")\n",
    "\n",
    "convert_to_coco(TRAIN_JSON, TRAIN_IMAGES_DIR, TRAIN_COCO_JSON)\n",
    "convert_to_coco(VAL_JSON, VAL_IMAGES_DIR, VAL_COCO_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f9879",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class BikePartsDataset(Dataset):\n",
    "    def __init__(self, images_dir, coco_json, transforms=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.transforms = transforms\n",
    "        with open(coco_json, 'r') as f:\n",
    "            self.coco = json.load(f)\n",
    "        self.images = self.coco[\"images\"]\n",
    "        self.annotations = self.coco[\"annotations\"]\n",
    "        \n",
    "        self.img_id_to_anns = {}\n",
    "        for ann in self.annotations:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id not in self.img_id_to_anns:\n",
    "                self.img_id_to_anns[img_id] = []\n",
    "            self.img_id_to_anns[img_id].append(ann)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        img_path = self.images_dir / img_info[\"file_name\"]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            raise\n",
    "        \n",
    "        anns = self.img_id_to_anns.get(img_info[\"id\"], [])\n",
    "\n",
    "        boxes, labels, states = [], [], []\n",
    "        for a in anns:\n",
    "            x, y, w, h = a[\"bbox\"]\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(a[\"category_id\"])\n",
    "            states.append(a[\"state_id\"])\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.as_tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4), dtype=torch.float32),\n",
    "            \"labels\": torch.as_tensor(labels, dtype=torch.int64) if labels else torch.zeros(0, dtype=torch.int64),\n",
    "            \"states\": torch.as_tensor(states, dtype=torch.int64) if states else torch.zeros(0, dtype=torch.int64),\n",
    "            \"image_id\": torch.tensor([img_info[\"id\"]], dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = BikePartsDataset(TRAIN_IMAGES_DIR, TRAIN_COCO_JSON, transform)\n",
    "val_dataset = BikePartsDataset(VAL_IMAGES_DIR, VAL_COCO_JSON, transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    prefetch_factor=1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    prefetch_factor=1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "print(f\"✅ Datasets ready: {len(train_dataset)} train, {len(val_dataset)} val\")\n",
    "print(f\"✅ Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271acd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MultiTaskFasterRCNN(nn.Module):\n",
    "    def __init__(self, num_parts, num_states):\n",
    "        super().__init__()\n",
    "        self.model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
    "        \n",
    "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_parts + 1)\n",
    "        \n",
    "        self.state_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_states)\n",
    "        )\n",
    "        self.state_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        if self.training and targets is not None:\n",
    "            losses = self.model(images, targets)\n",
    "            \n",
    "            state_loss = torch.tensor(0.0, device=images[0].device)\n",
    "            \n",
    "            for i, target in enumerate(targets):\n",
    "                if 'states' in target and len(target['states']) > 0:\n",
    "                    features = self.model.backbone(images)\n",
    "                    if isinstance(features, torch.Tensor):\n",
    "                        features = {'0': features}\n",
    "                    \n",
    "                    proposals, _ = self.model.rpn(images, features, targets)\n",
    "                    if len(proposals[i]) > 0:\n",
    "                        box_features = self.model.roi_heads.box_roi_pool(features, proposals, images, targets)\n",
    "                        box_features = self.model.roi_heads.box_head(box_features)\n",
    "                        \n",
    "                        if len(box_features) > 0:\n",
    "                            num_valid = min(len(box_features), len(target['states']))\n",
    "                            state_logits = self.state_head(box_features[:num_valid])\n",
    "                            state_targets = target['states'][:num_valid].to(state_logits.device)\n",
    "                            state_loss = state_loss + self.state_loss_fn(state_logits, state_targets)\n",
    "            \n",
    "            if isinstance(state_loss, torch.Tensor) and state_loss.requires_grad:\n",
    "                losses['loss_state'] = state_loss * 0.5\n",
    "            \n",
    "            total_loss = sum(v for v in losses.values() if isinstance(v, torch.Tensor))\n",
    "            return total_loss, losses\n",
    "        else:\n",
    "            return self.model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b990d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(TRAIN_COCO_JSON, 'r') as f:\n",
    "    train_coco = json.load(f,strict=False)\n",
    "    \n",
    "num_parts = len(train_coco[\"categories\"])\n",
    "num_states = 4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model = MultiTaskFasterRCNN(num_parts, num_states).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (imgs, targets) in enumerate(pbar):\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        if scaler is not None:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                loss, losses_dict = model(imgs, targets)\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss, losses_dict = model(imgs, targets)\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "        train_losses.append(loss.item() * gradient_accumulation_steps)\n",
    "        \n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            if scaler is not None:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            log_dict = {f\"train_{k}\": v.item() if isinstance(v, torch.Tensor) else v for k, v in losses_dict.items()}\n",
    "            log_dict[\"train_loss\"] = loss.item() * gradient_accumulation_steps\n",
    "            wandb.log(log_dict)\n",
    "        \n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item() * gradient_accumulation_steps:.4f}\"})\n",
    "        \n",
    "        if torch.cuda.is_available() and batch_idx % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            imgs = [img.to(device) for img in imgs]\n",
    "            targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    loss, losses_dict = model(imgs, targets)\n",
    "            else:\n",
    "                loss, losses_dict = model(imgs, targets)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        wandb.save(str(MODEL_SAVE_PATH))\n",
    "        print(f\"  ✅ Saved best model (val_loss: {avg_val_loss:.4f})\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n✅ Training completed! Best model saved to {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641ccb1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs, targets = next(iter(val_loader))\n",
    "    img = imgs[0].to(device)\n",
    "    output = model([img])[0]\n",
    "\n",
    "print(f\"Predicted boxes: {output['boxes'].shape}\")\n",
    "print(f\"Predicted labels: {output['labels'].shape}\")\n",
    "print(f\"Scores: {output['scores'][:5].cpu().numpy()}\")\n",
    "\n",
    "img_tensor = img.cpu().permute(1, 2, 0).clamp(0, 1)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_tensor)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Predictions: {len(output['boxes'])} detections\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ad4e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
